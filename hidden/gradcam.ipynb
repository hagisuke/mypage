{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMAM4xsOv8uiRkHPlS/REES"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"5Sjiml5SaJOb"},"source":["# ref\n","## https://github.com/ismailuddin/gradcam-tensorflow-2/\n","## https://github.com/kazuto1011/grad-cam-pytorch/\n","\n","# for make class\n","## https://github.com/nguyenhoa93/GradCAM_and_GuidedGradCAM_tf2/tree/master/src\n","## https://github.com/fitushar/3D-GuidedGradCAM-for-Medical-Imaging/blob/master/guided_Gradcam3.py\n","%matplotlib inline\n","\n","import random\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import tensorflow as tf\n","from tensorflow.keras.preprocessing.image import load_img\n","from tensorflow.keras.applications.resnet50 import (\n","    ResNet50,\n","    preprocess_input,\n","    decode_predictions,\n",")\n","import cv2\n","\n","image = np.array(load_img(\"./cat.jpg\", target_size=(224, 224, 3)))\n","plt.imshow(image)\n","\n","# prepare model\n","model = ResNet50()\n","last_conv_layer = model.get_layer(\"conv5_block3_out\")\n","last_conv_layer_model = tf.keras.Model(model.inputs, last_conv_layer.output)\n","\n","classifier_input = tf.keras.Input(shape=last_conv_layer.output.shape[1:])\n","x = classifier_input\n","for layer_name in [\"avg_pool\", \"predictions\"]:\n","    x = model.get_layer(layer_name)(x)\n","classifier_model = tf.keras.Model(classifier_input, x)\n","\n","# Grad-CAM\n","with tf.GradientTape() as tape:\n","    inputs = image[np.newaxis, ...] # (N,H,W,C))\n","    last_conv_layer_output = last_conv_layer_model(inputs) # (N,H,W,C)\n","    tape.watch(last_conv_layer_output)\n","    preds = classifier_model(last_conv_layer_output) # (N,C)\n","    top_pred_index = tf.argmax(preds[0])\n","    top_class_channel = preds[:, top_pred_index]\n","grads = tape.gradient(top_class_channel, last_conv_layer_output)\n","pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)) # 0=N,1=H,2=W\n","last_conv_layer_output = last_conv_layer_output.numpy()[0]\n","pooled_grads = pooled_grads.numpy()\n","for i in range(pooled_grads.shape[-1]):\n","    last_conv_layer_output[:, :, i] *= pooled_grads[i]\n","\n","# Average over all the filters to get a single 2D array\n","gradcam = np.mean(last_conv_layer_output, axis=-1) # (H,W)\n","# Clip the values (equivalent to applying ReLU)\n","# and then normalise the values\n","gradcam = np.clip(gradcam, 0, np.max(gradcam)) / np.max(gradcam)\n","gradcam = cv2.resize(gradcam, (224, 224))\n","plt.imshow(image)\n","plt.imshow(gradcam, alpha=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"E2hcaC-x_XmC"},"source":["# Counterfactual explanation\n","multiobject_image = np.array(\n","    load_img(\"../data/cat_and_dog.jpg\", target_size=(224, 224, 3))\n",")\n","with tf.GradientTape() as tape:\n","    inputs = multiobject_image[np.newaxis, ...]\n","    last_conv_layer_output = last_conv_layer_model(inputs)\n","    tape.watch(last_conv_layer_output)\n","    preds = classifier_model(last_conv_layer_output)\n","    top_pred_index = tf.argmax(preds[0])\n","    top_class_channel = preds[:, top_pred_index]\n","grads = tape.gradient(top_class_channel, last_conv_layer_output)\n","pooled_grads = tf.reduce_mean(-1 * grads, axis=(0, 1, 2))\n","last_conv_layer_output = last_conv_layer_output.numpy()[0]\n","pooled_grads = pooled_grads.numpy()\n","for i in range(pooled_grads.shape[-1]):\n","    last_conv_layer_output[:, :, i] *= pooled_grads[i]\n","\n","# Average over all the filters to get a single 2D array\n","ctfcl_gradcam = np.mean(last_conv_layer_output, axis=-1)\n","# Normalise the values\n","ctfcl_gradcam = np.clip(ctfcl_gradcam, 0, np.max(ctfcl_gradcam)) / np.max(ctfcl_gradcam)\n","ctfcl_gradcam = cv2.resize(ctfcl_gradcam, (224, 224))\n","plt.imshow(multiobject_image)\n","plt.imshow(ctfcl_gradcam, alpha=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Edlp-sgDIsy"},"source":["# Guided Grad-CAM1\n","with tf.GradientTape() as tape:\n","    inputs = image[np.newaxis, ...]\n","    last_conv_layer_output = last_conv_layer_model(inputs)\n","    tape.watch(last_conv_layer_output)\n","    preds = classifier_model(last_conv_layer_output)\n","    top_pred_index = tf.argmax(preds[0])\n","    top_class_channel = preds[:, top_pred_index]\n","grads = tape.gradient(top_class_channel, last_conv_layer_output)[0]\n","last_conv_layer_output = last_conv_layer_output[0]\n","guided_grads = (\n","    tf.cast(last_conv_layer_output > 0, \"float32\")\n","    * tf.cast(grads > 0, \"float32\")\n","    * grads\n",")\n","pooled_guided_grads = tf.reduce_mean(guided_grads, axis=(0, 1)) #0=H,1=W\n","guided_gradcam = np.ones(last_conv_layer_output.shape[:2], dtype=np.float32)\n","for i, w in enumerate(pooled_guided_grads):\n","    guided_gradcam += w * last_conv_layer_output[:, :, i]\n","guided_gradcam = cv2.resize(guided_gradcam.numpy(), (224, 224))\n","guided_gradcam = np.clip(guided_gradcam, 0, np.max(guided_gradcam))\n","guided_gradcam = (guided_gradcam - guided_gradcam.min()) / (\n","    guided_gradcam.max() - guided_gradcam.min()\n",")\n","plt.imshow(image)\n","plt.imshow(guided_gradcam, alpha=0.5)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"30AYYa7cFgD8"},"source":["# Guided Grad-CAM2\n","@tf.custom_gradient\n","def guided_relu(x):\n","    def grad(dy):\n","        return tf.cast(dy > 0, \"float32\") * tf.cast(x > 0, \"float32\") * dy\n","\n","    return tf.nn.relu(x), grad\n","\n","class GuidedBackprop:\n","    def __init__(self, model, layer_name: str):\n","        self.model = model\n","        self.layer_name = layer_name\n","        self.gb_model = self.build_guided_model()\n","\n","    def build_guided_model(self):\n","        gb_model = tf.keras.Model(\n","            self.model.inputs, self.model.get_layer(self.layer_name).output\n","        )\n","        layers = [\n","            layer for layer in gb_model.layers[1:] if hasattr(layer, \"activation\")\n","        ]\n","        for layer in layers:\n","            if layer.activation == tf.keras.activations.relu:\n","                layer.activation = guided_relu\n","        return gb_model\n","\n","    def guided_backprop(self, image: np.ndarray):\n","        with tf.GradientTape() as tape:\n","            inputs = tf.cast(image, tf.float32)\n","            tape.watch(inputs)\n","            outputs = self.gb_model(inputs)\n","        grads = tape.gradient(outputs, inputs)[0]\n","        return grads\n","\n","gb = GuidedBackprop(model, \"conv5_block3_out\")\n","saliency_map = gb.guided_backprop(image[np.newaxis, ...]).numpy() # (H,W,C)\n","saliency_map = saliency_map * np.repeat(guided_gradcam[..., np.newaxis], 3, axis=2)\n","saliency_map -= saliency_map.mean()\n","saliency_map /= saliency_map.std() + tf.keras.backend.epsilon()\n","saliency_map *= 0.25\n","saliency_map += 0.5\n","saliency_map = np.clip(saliency_map, 0, 1)\n","saliency_map *= (2 ** 8) - 1\n","saliency_map = saliency_map.astype(np.uint8)\n","plt.imshow(saliency_map)"],"execution_count":null,"outputs":[]}]}