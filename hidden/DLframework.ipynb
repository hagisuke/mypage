{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"DLframework.ipynb","provenance":[],"collapsed_sections":["ljP3NPc71P5x","wJ8voTj31hS1","wZm0XMtp1u4B"],"authorship_tag":"ABX9TyPpqMERXXF1X8hudXVLRCuZ"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"ljP3NPc71P5x"},"source":["# モデルのSave/Load"]},{"cell_type":"code","metadata":{"id":"Ps3WHvS6tCz9"},"source":["# chainer\n","model_path = 'model.hdf5'\n","chainer.serializers.save_hdf5(model_path, model)\n","chainer.serializers.load_hdf5(model_path, model)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nXqq01Zi1Oww"},"source":["# pytorch\n","model_path = 'model.pth'\n","torch.save(model.state_dict(), model_path) # for gpu\n","torch.save(model.to('cpu').state_dict(), model_path) # for cpu\n","model.load_state_dict(torch.load(model_path))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_2QB8aPa1dck"},"source":["# tensorflow v1\n","model_path = 'model'\n","with tf.Session() as sess:\n","    saver = tf.train.Saver()\n","    saver.save(sess, model_path)\n","    saver.restore(sess, model_path)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nPV-Q3VX1dSc"},"source":["# tensorflow v2\n","model_path = 'model'\n","tf.saved_model.save(model, model_path)\n","model = tf.saved_model.load(model_path)\n","\n","# この他にもtf.keras.models.save_modelやmodel.save_weights()やmodel.to_json()を使った方法がある"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wJ8voTj31hS1"},"source":["# カスタムデータセット"]},{"cell_type":"code","metadata":{"id":"9XYMTG9RtEyZ"},"source":["# chainer\n","class CustomDataset(chainer.dataset.DatasetMixin):\n","    def __init__(self, images_path, image_size, labels_path, dtype=np.float32):\n","        self._images_path = images_path\n","        self._image_size = image_size\n","        self._labels_path = labels_path\n","        self._dtype = dtype\n","\n","        self._images = []\n","        self._labels = []\n","        images = os.listdir(self._images_path)\n","        labels = [0] * len(images)\n","        # 以下のようにファイルから読み込むパターンもある\n","        #for line in open(self._labels_path):\n","        #  self._labels.append(int(line.strip()))\n","\n","        for image, label in zip(images, labels):\n","            self._images.append(image)\n","            self._labels.append(label)\n","\n","    def __len__(self):\n","        # データセットの数を返す\n","        return len(self._images_path)\n","\n","    def get_example(self, index):\n","        # データセットのインデックスを受け取ってデータを返す\n","        image = self._images[index]\n","        label = self._labels[index]\n","        with open(image, 'rb') as f:\n","            image = Image.open(f)\n","            image = image.convert('RGB')\n","        image = image.resize(self._image_size)\n","        image = np.asarray(image, dtype=self._dtype)\n","        image = image.transpose(2, 0, 1) # PILのImageは(height, width, channel)なのでChainerの形式に変換\n","        return image, np.array(label)\n","\n","custom_dataset = CustomDataset(images_path, (64, 64), labels_path)\n","train_iter = iterators.SerialIterator(dataset=custom_dataset, batch_size=64, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x-p-XKk81xSH"},"source":["# pytorch\n","class CustomDataset(torch.utils.data.Dataset):\n","    def __init__(self, transform=None):\n","        self.transform = transform\n","        self.images = []\n","        self.labels = []\n","        images_path = \"images_path\"\n","        images = os.listdir(images_path)\n","        labels = [0] * len(images)\n","        # 以下のようにファイルから読み込むパターンもある\n","        #for line in open(os.path.join(root_path, name + '.txt')):\n","        #  self.labels.append(int(line.strip()))\n","\n","        for image, label in zip(images, labels):\n","            self.images.append(image)\n","            self.labels.append(label)\n","\n","    def __getitem__(self, index):\n","        # データセットのインデックスを受け取ってデータを返す\n","        image = self.images[index]\n","        label = self.labels[index]\n","        with open(image, 'rb') as f:\n","            image = Image.open(f)\n","            image = image.convert('RGB')\n","        if self.transform:\n","            image = self.transform(image)\n","        return image, np.array(label)\n","\n","    def daya(self):\n","        # データセットの数を返す\n","        return len(self.images)\n","\n","custom_dataset = CustomDataset(transform=torchvision.transforms.ToTensor()))\n","train_loader = torch.utils.data.DataLoader(dataset=custom_dataset, batch_size=64, shuffle=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"7bdWuTPO1qaA"},"source":["# tensorflow v1\n","\n","# 基本的にデータセットはNHWCの4階テンソルNumpy配列で与えればよい\n","class CustomDataset:\n","    def __init__(self, images_path, image_size, labels_path, dtype=np.float32):\n","        self._images_path = images_path\n","        self._image_size = image_size\n","        self._labels_path = labels_path\n","        self._dtype = dtype\n","        self._index_in_epoch = 0\n","        self._epochs_completed = 0\n","\n","        self._images = []\n","        self._labels = []\n","        images = os.listdir(self._images_path)\n","        labels = [0] * len(images)\n","        # 以下のようにファイルから読み込むパターンもある\n","        #for line in open(self._labels_path):\n","        #  self._labels.append(int(line.strip()))\n","\n","        for image, label in zip(images, labels):\n","            self._images.append(image)\n","            self._labels.append(label)\n","\n","    def next_batch(self, batch_size, shuffle=False):\n","        # バッチサーズの分だけデータを返す\n","        start = self._index_in_epoch\n","        self._index_in_epoch += batch_size\n","        if self._index_in_epoch > self.datanum():\n","            # 1 epoch終わった後の処理\n","            self._epochs_completed += 1\n","            perm = np.arange(self.datanum())\n","            if shuffle:\n","                np.random.shuffle(perm)\n","            self._images = self._images[perm]\n","            self._labels = self._labels[perm]\n","            start = 0\n","            self._index_in_epoch = batch_size\n","        end = self._index_in_epoch\n","        \n","        image = self._images[start:end]\n","        label = self._labels[start:end]\n","        image_arr = []\n","        for image_ele in image:\n","            with open(image_ele, 'rb') as f:\n","                image_ele = Image.open(f)\n","                image_ele = image_ele.convert('RGB')\n","            image_ele = image_ele.resize(self._image_size)\n","            image_arr.append(image_ele)\n","        image = np.asarray(image_arr, dtype=self._dtype)\n","        return image, np.array(label)\n","\n","    def datanum(self):\n","        # データセットの数を返す\n","        return len(self._images_path)\n","\n","custom_dataset = CustomDataset(images_path, (64, 64), labels_path)\n","with tf.Session(config=config) as sess:\n","    # ・・・\n","    train_images, train_labels = custom_dataset.next_batch(batch_size=64, shuffle=True)\n","    # ・・・"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"okZFfs2P1uBZ"},"source":["# tensorflow v2\n","\n","def load_and_preprocess_image(path):\n","  # pathの画像を読み込み正規化する関数\n","  image = tf.io.read_file(path)\n","  image = tf.image.decode_jpeg(image, channels=3)\n","  image = tf.image.resize(image, [64, 64])\n","  image /= 255.0\n","  return image\n","\n","all_images_path = os.listdir(images_path)\n","all_labels = [0] * len(all_images_path)\n","path_ds = tf.data.Dataset.from_tensor_slices(all_images_path)\n","image_ds = path_ds.map(load_and_preprocess_image) # 前処理を適用\n","label_ds = tf.data.Dataset.from_tensor_slices(all_label)\n","custom_dataset = tf.data.Dataset.zip((image_ds, label_ds))\n","# 前処理が無ければ最初から画像とラベルを以下のように与えても良い\n","# custom_dataset = tf.data.Dataset.from_tensor_slices((all_images, all_labels)).batch(batch_size=64)\n","custom_dataset = custom_dataset.apply(tf.data.experimental.shuffle_and_repeat(buffer_size=len(all_images_path)))\n","custom_dataset = custom_dataset.batch(64).prefetch(tf.data.experimental.AUTOTUNE)\n","train_images, train_labels = next(iter(custom_dataset))\n","\n","# datasetをTFRecordに書きこんで読み込みを早くすることも可能\n","# https://www.tensorflow.org/tutorials/load_data/images?hl=ja"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wZm0XMtp1u4B"},"source":["# tensorflow v2"]},{"cell_type":"code","metadata":{"id":"kIul_wz5NMyj"},"source":["# MLP\n","# https://www.tensorflow.org/tutorials/quickstart/advanced?hl=ja\n","import tensorflow as tf\n","\n","# 1.データセットの準備部分\n","batch_size = 50         # ミニバッチのサイズ\n","mnist = tf.keras.datasets.mnist\n","\n","(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n","train_images, test_images = train_images / 255.0, test_images / 255.0\n","\n","train_ds = tf.data.Dataset.from_tensor_slices(\n","    (train_images, train_labels)).shuffle(10000).batch(batch_size)\n","test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)\n","\n","# 2.モデルの作成部分\n","learning_rate = 0.001   # 学習率\n","training_epochs = 5     # エポック数\n","\n","class MLPModel(tf.keras.Model):\n","\n","    def __init__(self):\n","        super(MLPModel, self).__init__()\n","        self.flat1 = tf.keras.layers.Flatten()\n","        self.dense1 = tf.keras.layers.Dense(64, activation='relu')\n","        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n","\n","    def call(self, inputs):\n","        h = self.flat1(inputs)\n","        h = self.dense1(h)\n","        return self.dense2(h)\n","\n","model = MLPModel()\n","\n","# 3.実行する部分\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy() # CategoricalCrossentropyと違い、ラベルのOne-hot化不要\n","optimizer = tf.keras.optimizers.Adam(learning_rate)\n","\n","train_loss = tf.keras.metrics.Mean(name='train_loss') # 損失の記録用\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy') # 精度の記録用\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n","\n","# 訓練用\n","@tf.function\n","def train_step(images, labels):\n","  with tf.GradientTape() as tape:\n","    predictions = model(images)\n","    loss = loss_object(labels, predictions)\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_loss(loss)\n","  train_accuracy(labels, predictions)\n","\n","# テスト用\n","@tf.function\n","def test_step(images, labels):\n","  predictions = model(images)\n","  t_loss = loss_object(labels, predictions)\n","\n","  test_loss(t_loss)\n","  test_accuracy(labels, predictions)\n","\n","# 学習開始\n","for epoch in range(training_epochs):\n","  for images, labels in train_ds:\n","    train_step(images, labels)\n","\n","  for test_images, test_labels in test_ds:\n","    test_step(test_images, test_labels)\n","\n","  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n","  print (template.format(epoch+1,\n","                         train_loss.result(),\n","                         train_accuracy.result()*100,\n","                         test_loss.result(),\n","                         test_accuracy.result()*100))\n","\n","  # 次のエポック用にメトリクスをリセット\n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_loss.reset_states()\n","  test_accuracy.reset_states()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"02cfQIdF1y2T","executionInfo":{"elapsed":65975,"status":"ok","timestamp":1622035802241,"user":{"displayName":"Keisuke Hagiwara","photoUrl":"","userId":"05789560385938525331"},"user_tz":-540},"outputId":"59bc9401-98a0-4023-af7a-93e5139d995a"},"source":["# CNN\n","import tensorflow as tf\n","\n","# 1.データセットの準備部分\n","batch_size = 50         # ミニバッチのサイズ\n","mnist = tf.keras.datasets.mnist\n","\n","(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n","train_images, test_images = train_images / 255.0, test_images / 255.0\n","train_images = train_images[..., tf.newaxis] # NHWC (Number, height, width, channel)の形にするため次元追加\n","test_images = test_images[..., tf.newaxis]   # .reshapeを使っても良い\n","\n","train_ds = tf.data.Dataset.from_tensor_slices(\n","    (train_images, train_labels)).shuffle(10000).batch(batch_size)\n","test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)\n","\n","# データ拡張を加える場合は以下のように書くこともできる\n","# datagen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=90)\n","# train_ds = datagen.flow(train_images, train_labels, batch_size, shuffle=True)\n","# test_ds = datagen.flow(test_images, test_labels, batch_size, shuffle=False)\n","\n","# 2.モデルの作成部分\n","learning_rate = 0.001   # 学習率\n","training_epochs = 5     # エポック数\n","dropout = 0.5           # 非ドロップアウト率\n","\n","class CNNModel(tf.keras.Model):\n","\n","    def __init__(self):\n","        super(CNNModel, self).__init__()\n","        self.conv1 = tf.keras.layers.Conv2D(filters=32, kernel_size=3, padding='same', activation='relu', input_shape=(28,28,1)) # input_shapeは無くても良い\n","        self.pool1 = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='same') # tf.keras.layers.MaxPool2Dとも書ける\n","        self.conv2 = tf.keras.layers.Conv2D(filters=64, kernel_size=3, padding='same', activation='relu')\n","        self.pool2 = tf.keras.layers.MaxPooling2D(pool_size=2, strides=2, padding='same')\n","        self.drop1 = tf.keras.layers.Dropout(dropout)\n","        self.flat1 = tf.keras.layers.Flatten()\n","        self.dense1 = tf.keras.layers.Dense(1024, activation='relu')\n","        self.dense2 = tf.keras.layers.Dense(10, activation='softmax')\n","\n","    def call(self, inputs):\n","        h = self.conv1(inputs)\n","        h = self.pool1(h)\n","        h = self.conv2(h)\n","        h = self.pool2(h)\n","        h = self.drop1(h)\n","        h = self.flat1(h)\n","        h = self.dense1(h)\n","        return self.dense2(h)\n","\n","model = CNNModel()\n","\n","# 3.実行する部分\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy() # CategoricalCrossentropyと違い、ラベルのOne-hot化不要\n","optimizer = tf.keras.optimizers.Adam(learning_rate)\n","\n","train_loss = tf.keras.metrics.Mean(name='train_loss') # 損失の記録用\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy') # 精度の記録用\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n","\n","# 訓練用\n","@tf.function\n","def train_step(images, labels):\n","  with tf.GradientTape() as tape:\n","    predictions = model(images)\n","    loss = loss_object(labels, predictions)\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_loss(loss)\n","  train_accuracy(labels, predictions)\n","\n","# テスト用\n","@tf.function\n","def test_step(images, labels):\n","  predictions = model(images)\n","  t_loss = loss_object(labels, predictions)\n","\n","  test_loss(t_loss)\n","  test_accuracy(labels, predictions)\n","\n","# 学習開始\n","for epoch in range(training_epochs):\n","  for images, labels in train_ds:\n","    train_step(images, labels)\n","\n","  for test_images, test_labels in test_ds:\n","    test_step(test_images, test_labels)\n","\n","  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n","  print (template.format(epoch+1,\n","                         train_loss.result(),\n","                         train_accuracy.result()*100,\n","                         test_loss.result(),\n","                         test_accuracy.result()*100))\n","\n","  # 次のエポック用にメトリクスをリセット\n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_loss.reset_states()\n","  test_accuracy.reset_states()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1, Loss: 0.10999956727027893, Accuracy: 96.58833312988281, Test Loss: 0.04337692633271217, Test Accuracy: 98.62999725341797\n","Epoch 2, Loss: 0.0377047173678875, Accuracy: 98.77999877929688, Test Loss: 0.04609948769211769, Test Accuracy: 98.54999542236328\n","Epoch 3, Loss: 0.025945182889699936, Accuracy: 99.13666534423828, Test Loss: 0.0295694712549448, Test Accuracy: 99.02999877929688\n","Epoch 4, Loss: 0.016230307519435883, Accuracy: 99.46333312988281, Test Loss: 0.03314388170838356, Test Accuracy: 98.90999603271484\n","Epoch 5, Loss: 0.014359348453581333, Accuracy: 99.53333282470703, Test Loss: 0.03502795472741127, Test Accuracy: 98.87999725341797\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cM8XGbVh1z9r"},"source":["# RNN\n","import tensorflow as tf\n","\n","# 1.データセットの準備部分\n","batch_size = 50         # ミニバッチのサイズ\n","mnist = tf.keras.datasets.mnist\n","\n","(train_images, train_labels),(test_images, test_labels) = mnist.load_data()\n","train_images, test_images = train_images / 255.0, test_images / 255.0\n","\n","train_ds = tf.data.Dataset.from_tensor_slices(\n","    (train_images, train_labels)).shuffle(10000).batch(batch_size)\n","test_ds = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(batch_size)\n","\n","# 2.モデルの作成部分\n","learning_rate = 0.001   # 学習率\n","training_epochs = 5     # エポック数\n","\n","n_in = 28    # 1時刻当たりのデータ数\n","n_time = 28  # 時系列の数\n","n_unit = 128 # 中間層のセルの数\n","\n","class RNNModel(tf.keras.Model):\n","\n","    def __init__(self):\n","        super(RNNModel, self).__init__()\n","        # 入力の形を明示するためにtf.keras.layers.InputLayer(input_shape=(28,28))を最初に入れても良い\n","        stacked_cells = [tf.keras.layers.LSTMCell(n_unit) for _ in range(3)]\n","        self.lstm1 = tf.keras.layers.RNN(stacked_cells, return_sequences=True)\n","        self.dense1 = tf.keras.layers.Dense(10, activation='softmax')\n","\n","    def call(self, inputs):\n","        h = self.lstm1(inputs)\n","        last_output = h[:,-1,:]\n","        h = self.dense1(last_output)\n","        return h\n","\n","# 以下のようにも書ける\n","#class RNNModel(tf.keras.Model):\n","#\n","#    def __init__(self):\n","#        super(RNNModel, self).__init__()\n","#        self.lstm1 = tf.keras.layers.LSTM(n_unit, return_sequences=True)\n","#        self.lstm2 = tf.keras.layers.LSTM(n_unit, return_sequences=True)\n","#        self.lstm3 = tf.keras.layers.LSTM(n_unit, return_sequences=False)\n","#        self.dense1 = tf.keras.layers.Dense(10, activation='softmax')\n","#\n","#    def call(self, inputs):\n","#        h = self.lstm1(inputs)\n","#        h = self.lstm2(h)\n","#        h = self.lstm3(h)\n","#        h = self.dense1(h)\n","#        return h\n","\n","model = RNNModel()\n","\n","# 3.実行する部分\n","loss_object = tf.keras.losses.SparseCategoricalCrossentropy() # CategoricalCrossentropyと違い、ラベルのOne-hot化不要\n","optimizer = tf.keras.optimizers.Adam(learning_rate)\n","\n","train_loss = tf.keras.metrics.Mean(name='train_loss') # 損失の記録用\n","train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy') # 精度の記録用\n","test_loss = tf.keras.metrics.Mean(name='test_loss')\n","test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n","\n","# 訓練用\n","@tf.function\n","def train_step(images, labels):\n","  with tf.GradientTape() as tape:\n","    predictions = model(images)\n","    loss = loss_object(labels, predictions)\n","  gradients = tape.gradient(loss, model.trainable_variables)\n","  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n","\n","  train_loss(loss)\n","  train_accuracy(labels, predictions)\n","\n","# テスト用\n","@tf.function\n","def test_step(images, labels):\n","  predictions = model(images)\n","  t_loss = loss_object(labels, predictions)\n","\n","  test_loss(t_loss)\n","  test_accuracy(labels, predictions)\n","\n","# 学習開始\n","for epoch in range(training_epochs):\n","  for images, labels in train_ds:\n","    train_step(images, labels)\n","\n","  for test_images, test_labels in test_ds:\n","    test_step(test_images, test_labels)\n","\n","  template = 'Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, Test Accuracy: {}'\n","  print (template.format(epoch+1,\n","                         train_loss.result(),\n","                         train_accuracy.result()*100,\n","                         test_loss.result(),\n","                         test_accuracy.result()*100))\n","\n","  # 次のエポック用にメトリクスをリセット\n","  train_loss.reset_states()\n","  train_accuracy.reset_states()\n","  test_loss.reset_states()\n","  test_accuracy.reset_states()"],"execution_count":null,"outputs":[]}]}